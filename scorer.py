# -*- coding: utf-8 -*-
"""
====================================SCORER=====================================

PROBLEM:
    The program is intended to calculate the accuracy of the tag file 
    generated from tagger.py by compairing it with the key file already 
    provided by the professor. It also generated the confsion matrix of all 
    the tags

USAGE:
    The program can be called via a command-line interface.
    It takes 2 arguments i.e. file1 & file2:
        file1 is the key file provided by the professor.
        file2 is the tag file generated by tagger.py of test file

COMMAND FORMAT:
    python scorer.py file1 file 2 > report

"report" is the file that will be generated that contains the accuracy of 
tagger.py and also generate a confusion matrix of all the tags in key file and
the tag file

EXAMPLE:
    if the key file has:
        No/RB ,/, 
        it/PRP
        was/VBD n't/RB Black/NNP Monday/NNP
    and the tag file generated from tagger.py has:
        No/DT ,/,
        it/PRP
        was/VBD n't/RB Black/NNP Monday/NNP
    
    Over here correct tags predicted= 6
    Over here Wrong tags predicted= 1
    Then it will calculate accuracy = correct/(correct+wrong)
                                    = 6/7
                                    = 0.85 or 85%
    Display confusion matrix as:
    Predicted   ,   DT  PRP  VBD  RB  NNP
    Actual
    ,           1   0   0    0    0   0
    RB          0   1   0    0    1   0
    PRP         0   0   1    0    0   0
    VBD         0   0   0    1    0   0
    NNP         0   0   0    0    0   2
 
ALGORITHM (Step-by-step):
    1. Takes key and tag file from the user in the format as mentioned
    2. Processes the key file - removes the square brackets, remove "/"
        replaces the OR symbols, tokenize it and converts the file in below format:
            [(word1, tag1), (word2, tag2), (word3, tag3),………… (wordN, tagN)]
        and save this list in 'tagged_sentences'
    3. Processes the tag file - removes the square brackets, remove "/"
        tokenize it and converts the file in below format:
            [(word1, tag1), (word2, tag2), (word3, tag3),………… (wordN, tagN)]
        and save this list in 'tested_sentences'
    4. Compared the tag word-by-word from key file and tag file using for loop
    5. if tag is correct in tag file, increment correct with 1 else increment
        wrong with 1
    6. Calculate the frequency using the formula:
        correct/(correct+wrong)
    7. To generate confusion matrix, all the tags of key file and tag file are
        saved in lists key_tags & test_tags respectively.
    8. Generated the confusion matrix from ConfusionMatrix function in nltk
    9. Then saved the report in report file using STDOUT

Author: Avneet Pal Kour & Paras Sethi
Date: 24-Feb-2018
"""

from __future__ import division
from nltk.metrics import ConfusionMatrix
import argparse 
import nltk
import time #to calculate the execution time
start = time.clock() # start of execution

# Takes key and tag file from the user in the format as mentioned
parser = argparse.ArgumentParser()
parser.add_argument(dest='file1', type=argparse.FileType('r')) 
parser.add_argument(dest='file2', type=argparse.FileType('r')) 
args = parser.parse_args()
ot = args.file1
ky = args.file2

# Processes the key file - removes the square brackets, remove "/", removes the 
#       2nd tag from the two joined tags so that only 1st one is considered, 
#       replaces the OR(\) symbols, tokenize it and converts the file in below format:
#            [(word1, tag1), (word2, tag2), (word3, tag3),………… (wordN, tagN)]
#       and save this list in 'tagged_sentences'
key=ky.read()
key=key.replace('[', '')
key=key.replace(']', '')
key=key.replace('\/', ' Paras ')
key=key.replace('/', ' ')
for ch in ['|JJR','|RBR','|JJ','|NN','|IN','|RB']:
    if ch in key:
        key=key.replace(ch, '')

c=nltk.WhitespaceTokenizer().tokenize(key)

tagged_sentences=[]
def my_range(start, end, step):
    while start < end:
        yield start
        start += step
r=len(c)
for i in my_range(0,r,1):
      if c[i]=='Paras':
          c[i]=c[i+2]
for i in my_range(0,r,2):
      f=(c[i],c[i+1])
      tagged_sentences.append(f)
      
# Processes the tag file - removes the square brackets, remove "/"
#        tokenize it and converts the file in below format:
#            [(word1, tag1), (word2, tag2), (word3, tag3),………… (wordN, tagN)]
#        and save this list in 'tested_sentences'
output=ot.read()
output=output.replace('/', ' ')
b=nltk.WhitespaceTokenizer().tokenize(output)

tested_sentences=[]

r=len(b)

for i in my_range(0,r,2):
      f=(b[i],b[i+1])
      tested_sentences.append(f)
      
correct=0
wrong=0

# Compared the tag word-by-word from key file and tag file using for loop
# if tag is correct in tag file, increment correct with 1 else increment
#        wrong with 1
for i in range(len(tagged_sentences)):
    if tested_sentences[i][0]==tagged_sentences[i][0]:
        if tested_sentences[i][1]==tagged_sentences[i][1]:
            correct+=1
        else:
            wrong+=1

#calculate accuracy
accuracy=correct/(correct+wrong)

key_tags=[]
test_tags=[]

# To generate confusion matrix, all the tags of key file and tag file are
#        saved in lists key_tags & test_tags respectively.
for i in range(len(tagged_sentences)):
    key_tags.append(tagged_sentences[i][1])
for i in range(len(tested_sentences)):
    test_tags.append(tested_sentences[i][1])

# Generated the confusion matrix from ConfusionMatrix function in nltk
cm = ConfusionMatrix(key_tags, test_tags) #generate confusion matrix

# Final Printing the below details in the report file
print("Hi!!! Below is the accuracy report of your tagger.")
print("Accuracy is: "+str("%.2f" % (accuracy*100))+"%\n")
print("Confusion matrix:\n%s" % cm.pretty_format(sort_by_count=True)) #print confusion matrix
end = time.clock() # end of execution


# Print the execution time
print("\nExecution time for scorer is %.2f" %(end-start) + " seconds")